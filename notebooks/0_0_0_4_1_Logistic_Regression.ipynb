{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, matthews_corrcoef, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Define the preprocessing steps as functions\n",
    "def replace_inf(df):\n",
    "    df_encoded = df.replace([np.inf], 1e6).replace([-np.inf], -1e6)\n",
    "    if 'prev_age_delta' in df_encoded.columns:\n",
    "        df_encoded['prev_age_delta'] = df_encoded['prev_age_delta'].fillna(0)\n",
    "    if 'prev_USD_amount' in df_encoded.columns:\n",
    "        df_encoded['prev_USD_amount'] = df_encoded['prev_USD_amount'].fillna(0)\n",
    "    return df_encoded\n",
    "\n",
    "def pipeline_init_(model, numerical_columns, categorical_columns):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', ColumnTransformer([\n",
    "            ('num_pipeline', Pipeline([\n",
    "                ('replace_inf', FunctionTransformer(replace_inf)),\n",
    "                ('scaler', MinMaxScaler())\n",
    "            ]), numerical_columns),\n",
    "            \n",
    "            ('cat_pipeline', Pipeline([\n",
    "                ('ohe', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "            ]), categorical_columns)\n",
    "        ])),\n",
    "        ('smote', SMOTE()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def get_features(feature_selection_df, n=20):\n",
    "    typological_features = [\n",
    "        'is_crossborder', \n",
    "        'under_threshold_14d_count',\n",
    "        'under_threshold_14d_sum',\n",
    "        'under_threshold_30d_count',\n",
    "        'under_threshold_30d_sum',\n",
    "        'under_threshold_7d_count',\n",
    "        'under_threshold_7d_sum'\n",
    "        ]\n",
    "    def_time_columns = ['txn_time_hr', 'txn_time_mm']\n",
    "    def_categorical_columns = ['std_txn_type', 'std_txn_method', 'prev_std_txn_type', 'prev_std_txn_method']\n",
    "\n",
    "\n",
    "    features = feature_selection_df[~feature_selection_df['Feature'].isin(typological_features)].nlargest(n, 'MI_Score').iloc[:,0].tolist() + typological_features\n",
    "\n",
    "    categorical_cols = list(set(features) & set(def_categorical_columns))\n",
    "    numerical_cols = list(set(features) - (set(categorical_cols) | set(def_time_columns)))\n",
    "\n",
    "    return features, categorical_cols, numerical_cols\n",
    "\n",
    "def calculate_informedness_markedness(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    # Calculate components\n",
    "    sensitivity = tp / (tp + fn)  # also called TPR\n",
    "    specificity = tn / (tn + fp)  # also called TNR\n",
    "    ppv = tp / (tp + fp)  # positive predictive value\n",
    "    npv = tn / (tn + fn)  # negative predictive value\n",
    "    \n",
    "    # Calculate metrics\n",
    "    informedness = sensitivity + specificity - 1\n",
    "    markedness = ppv + npv - 1\n",
    "    \n",
    "    return informedness, markedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet('../data/split/resplit/ds3_train.parquet').drop(columns=['Time_step', 'Transaction_Id', 'Transaction_Type','party_Id',\n",
    "       'party_Account', 'party_Country', 'cparty_Id', 'cparty_Account',\n",
    "       'cparty_Country',])\n",
    "df_test = pd.read_parquet('../data/split/resplit/ds3_test.parquet').drop(columns=['Time_step', 'Transaction_Id', 'Transaction_Type','party_Id',\n",
    "       'party_Account', 'party_Country', 'cparty_Id', 'cparty_Account',\n",
    "       'cparty_Country',])\n",
    "\n",
    "X_train  = df_train.drop(columns=['Label'])\n",
    "y_train = df_train['Label']\n",
    "\n",
    "X_test  = df_test.drop(columns=['Label'])\n",
    "y_test = df_test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9815208385022023\n",
      "MCC: 0.9619719075767297\n",
      "Informedness: 0.9406413780593141\n",
      "Markedness: 0.9837861405544714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    691344\n",
      "           1       1.00      0.94      0.97    175250\n",
      "\n",
      "    accuracy                           0.99    866594\n",
      "   macro avg       0.99      0.97      0.98    866594\n",
      "weighted avg       0.99      0.99      0.99    866594\n",
      "\n",
      "Time to train: 10.55804181098938\n"
     ]
    }
   ],
   "source": [
    "features, categorical_cols, numerical_cols = get_features(pd.read_csv('../data/feature_selection/ds3_mi_to_target.csv'), df_train.columns, 5)\n",
    "pipeline = pipeline_init_(LogisticRegression(), numerical_cols, categorical_cols)\n",
    "\n",
    "# Time\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Time\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "informedness, markedness = calculate_informedness_markedness(y_test, y_pred)\n",
    "\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "print(f'MCC: {mcc}')\n",
    "print(f'Informedness: {informedness}')\n",
    "print(f'Markedness: {markedness}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Time to train: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = pipeline.named_steps['classifier']\n",
    "feature_importances = classifier_model.coef_[0]\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscds_dsrtn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
